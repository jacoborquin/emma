% -----------------------------------------------------------------------------
% Review
% -----------------------------------------------------------------------------

\singlespacing
\begin{center}

{\Large \textbf{REVIEWS FOR:}}

\vspace{1cm}

{\Large \textbf{The visual environment and attention in decision making}}

\vspace{5mm}

% \textbf{authors...}

\vspace{1cm}
\end{center}


% -----
% Editor
% -----

\section{Editor}
\label{rev:editor}

\subsection{Overall evaluation}

% by using square brackets we can optionally create comment label that we can use later on
\com[com-editor]{Thank you for submitting "The visual environment, attention and decision making" for review and consideration for publication in Psychological Bulletin. The editorial board has completed its review. In addition to reading the manuscript myself, I was fortunate to have received reviews from three outstanding experts in the field. Their feedback is detailed and constructive, and I am grateful to them for their time and thoughtfulness.\\
\\
As you will see from the reviews, most of us noted that this work was conducted in a generally thorough manner and we all generally got a sense that it has some potential as a contribution to the literature. However, there are also several issues that require consideration. I will now summarize points that I viewed as central that were raised by the reviewers, provide some feedback of my own along the way, and conclude with my recommendation.
%
\begin{itemize}
    \item My impression was that Reviewer 1 was concerned that the ultimate impact of this work might be unclear because, in its current form, it would only capture the interest of researchers who are already aware of the issues it raises. As such, it remains possible that progress might occur without requiring the publication of this meta-analysis. In my view, this mitigates the potential contribution of this work and would require some efforts on your part to appeal to a broader audience.
    \item Reviewer 2 noted that there were issues with the structure of the paper that affected its readability. I agree that the method should come immediately after the introduction, as is standard for APA journals.
    \item Reviewer 2 also raised the need to discuss more deeply the role of visual factors to clarify this paper’s potential impact.
    \item Finally, Reviewer 3 raised a number of critical issues that would clarify the scope and theoretical contribution of this work.
\end{itemize}
%
Based on these brief highlights, I would expect that the reviewers’ comments can be addressed but some of them will require tight arguments, especially when addressing concerns relevant to the impact of this paper. Therefore, I invite you to submit a revision that addresses all the the points raised by the reviewers. Please let me know within a week if you will be sending us a revision by replying to this message. If you chose to resubmit, please do so within 3 months of receipt of this letter.}

We thank you and the reviewers for the comprehensive evaluation of our manuscript and the encouraging comments. We are grateful to you for pointing out the most important comments from the reviewers. In the revised manuscript we have now introduced line numbers and for each comment we refer to a line in the document where we have introduced a major change. To facilitate the revision we have also marked major changes in the main text with red color. 

We have provided thorough responses to each comment under the section for respective reviewer, but will briefly summarize the main points here. To the first point from Reviewer 1 concerning the impact we have revised the introduction so that it now addresses a broader audience from not only cognitive science, but also the disciplines economics, marketing, management, hospitality and transportation research. We have also written a longer section on the structure of the visual environment which should clarify the relevance of visual factors in representative design across all these disciplines. Regarding Reviewer 2's points, we have aligned the structure of the manuscript sections to APA standards and expanded the section on visual factors to better clarify the contribution of the manuscript. Regarding Reviewer 3, we have addressed all points including the request for access to less aggregate (raw) data. Providing this required an extensive recoding of all included studies and in view of the effort we decided to use the new data to strengthen the manuscript further. We have therefore included a new section on descriptive eye movements that provides basic information about average fixation likelihood and counts across all studies as well as intuitive results expressing effect sizes in these metrics instead of correlation coefficients.    

\com[com-editor-litsearch]{If you decide to prepare a revision, please also address the following technical points: The literature search was conducted over 2 years ago. You should consider updating the sample.}
    
We have now conducted an updated literature search, covering the period from 2018 to October 2020, which resulted in 11 new articles, bringing a total to 69. Corresponding section in Methods has been updated (see line~\lineref{litsearch} and line~\lineref{inclusion}) as well as the PRISMA flow figure (Figure~\ref{fig:flow_diagram}).
    
    
\com[com-editor-evaluation]{You state on page 9 that “some experiments operationalized more than one factor”, suggesting that not all your effect sizes were independent. If that is the case, multilevel analysis with robust variance estimates should be considered to handle the dependence in effect sizes and sampling variances. It is likely that the Hunter \& Schmidt correction could still be applied in this context (see Johnson et al, 1995: \url{https://doi.org/10.1037/0021-9010.80.1.94}). In any case, this point requires clarification and possible changes to your analysis.}

Thank you for this suggestion. We have implemented it in our analysis and now a ``sandwich'' estimator is used with a small-sample adjustment \citep{hedges2010} (see line~\lineref{sandwich-methods}). The results did not change substantially based on this change.


\com[com-editor-evaluation]{Like reviewer 2, I would like to see more clarity about the publication bias analysis. In addition, trim and fill is not a means to investigate the presence of a publication bias but more a way to correct for it when it is identified. “Eyeballing” the funnel plots as you did is not valid either. A more thorough approach should be considered. For a summary of available approaches, see Table 2 in van Aert et al. (2019; \url{https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0215052}).}

Indeed, trim-and-fill only attempts to correct the effect sizes, not to identify whether publication bias exists. We also agree that we should be able to do better than just eye balling the funnel plots. As we explain in a response to reviewer 2 (see \ref{com-r2-publication-bias}), to identify the existence of a publication bias we have now included a PET-PEESE analysis and a new type of analysis based on the coding of studies citing public grants (see line~\lineref{PB-PET}). We explain these new analyses in details in the Methods section (see line~\lineref{pubbias-intro}). 


\com[com-editor-evaluation]{You should avoid presenting the same material both in tables and in the text to streamline the paper.}

We did our best to eliminate such redundancies throughout the Results section.


\com[com-editor-evaluation]{For the sake of reproducibility, please state in the paper which R package(s) you used in your data analyses.}

In Methods we already state which R packages we have used in our analyses, specifying the packages in a list of references:

\quotetext{Analyses were performed in R programming language with the help of several additional libraries \citep{R2020,datatable,tidyverse,metafor,irr,lme4,lmerTest,xtable,extrafont}.}

However, in our experience this is far from enough for reproducibility. This is why we are providing the data and all the code in an Open Science Repository (\url{https://osf.io/buk7p/}), readers with a bit of programming skills should have easy time reproducing all the analyses. We have added a reminder about this resource immediately after specifying libraries (see line~\lineref{OSF-pointer}). 


\com[com-editor-evaluation]{Also, please add a Public Significance Statement below the abstract in the masked manuscript file. \url{http://www.apa.org/pubs/authors/guidance.aspx}}

We have added a Public Significance Statement below the abstract. 


% -----
% Reviewer 1
% -----

\section{Reviewer 1}
\label{rev:r1}

\subsection{Overall evaluation}
\label{rev:r1sum}

\com[com-r1-evaluation]{The paper is concerned with the role that aspects of the visual environment (e.g., salience, position, surface size), as opposed to internal, cognitive factors (e.g., heuristics and biases), play in decision making. Past decision-making research that employed visual displays focused on cognitive processes that followed encoding of the experimental stimuli, and ignored possible effects driven by features of the visual environment. Though this strategy no doubt simplified the problem space for these researchers by, in effect, controlling the broader context of stimulus input, the authors claim that ignoring visual features of the environment that are inevitably present in real-work circumstances has compromised the external validity of such work. The authors present a meta-analysis to support their claim that complete models of attention and decision making must include some accounting of the visual environment, and the work of the eyes.\\
\\
There's much to like in the approach the authors are taking. In effect, they are calling out the decision-making field for ignoring the world of bottom-up visual processes in favor of a focus on the (perhaps) more interesting top-down cognitive processes. That is, decision making theorists have taken an "all-things-being-equal" attitude toward the visual environment from which decision-related stimuli are sampled, but in the real world all visual scenes are not equal, so decision theorists need to model eye movements, stimulus-driven capture of attention, and other vision-based variables if they want complete models. The overall contribution of the paper is as a call for the field to integrate cognitive and visual processes in models of attention and decision making.} 

We thank you for a concise summary and we are very happy that you liked our approach.  We are grateful for suggestions for improving the manuscript, we address each of them below. In the revised manuscript we have now introduced line numbers and for each comment we refer to a line in the document where we have introduced a major change. To facilitate the revision we have also marked major changes in the main text with red color.


\subsection{Comments}

\com[com-r1-praise]{The structural aspects of the meta-analysis are sound. The effects are clear, if not impressive. The paper is well-written and should be accessible to a non-specialist audience.}

Thank you for the feedback, in particular it is good to know that our writing strikes a right balance. Regarding effect sizes please note that they have changed in the revision. We updated the literature search and included 11 new articles. Some effect sizes did became larger (e.g. salience), but the most important point is that when taking into account publication bias we now see that visual factors play a larger role than cognitive factors. 


\com[com-r1-field-divisions]{Overall, however, I'm somewhat mixed about this paper. On the plus side, the authors have revealed that an important branch of cognitive science has overlooked systematic sources of variance that could be - and should be - modeled. Moreover, their analysis yields some fairly specific directions for future research. On the minus side, it's not clear what the ultimate impact of this paper will be. In many cognitive departments vision science anchors one end of the processing spectrum while higher-level areas such as decision-making anchor a distant, opposite end. Those who are most likely to respond to this call are those already aware of the situation. Which leads to a related concern: Is this call, in fact, needed for progress to be made? While reading this ms I found myself occasionally thinking "Right - well then why don't you go ahead and just do the studies that you claim should be done?"}

We are very pleased that you share our view of the need to integrate visual factors in decision research, but we remain sceptical that progress in this direction is likely to happen by itself. You ask why we do not just go ahead and do the required work. We are indeed preparing work with the aim of integrating cognitive and visual processes in models of attention and decision making. Even with a generous assumption that other teams working at this intersection are working or planning to work on similar ideas, we believe this will not be sufficient to achieve such integration. Theoretical challenges and model development look daunting at the moment, and it is highly unclear whether a handful of teams can make a serious dent in a reasonable time frame. Hence, our call to action needs to reach broader audience of vision scientists and decision making scholars. The reach of the issues we raise goes beyond vision science and decision making, however -- attention plays an important role in theories outside of these two domains. We acknowledge that this was not clear in the initial manuscript and have added a paragraph reviewing theories on attention and decision making from other disciplines (see line~\lineref{r222}). We show that disciplines such as economics, marketing, management and organizational research, resource economics, hospitality and transportation research all have well developed concepts of attention and decision making, and that in all cases attention is strictly seen as a top-down cognitive process. We hope that our call to action will result in diverse set of contributions from all of the disciplines.\\

Admittedly, many decision making scholars tend to view visual factors as nuisance variables that rational decision makers (should) ignore. This can also be seen in a comment made by reviewer 3 (see comment \ref{com-r3-salience}): 

\quotetext{One problems with salience in the context of choice is that people deliberately try to counteract it since they might become aware of the manipulation intention, or they want to be rational and look at all information (at least once)}. 

%In our opinion, the comment does not hold for all studies, mainly for simple standard paradigms with few options (risky choice, strategic choice, intertemporal choice etc.), but still, these paradigms account for a large portion of decision making research.
To reduce the chances that decision making researchers ignore our results and call to action, we opted for providing additional arguments why visual factors should not be viewed as nuisance variables. In a new section on the visual environment we have explored the relation between the visual and cognitive factors (starting at line~\lineref{vis-env}). We show that visual factors in natural environments are highly correlated with decision relevant cognitive factors, e.g. salience, size, and position are ecologically valid predictors of product attributes, product popularity and even of product price. When experimentally eliminating or randomizing away visual factors, as is usual in simple standard paradigms in decision making, the experimenter removes any ecological validity of visual factors, and therefore, it is not surprising that participants in these experiments would ignore salience (or any other visual factor). With these arguments and with the effect sizes of visual factors, we hope to, at the very least, make decision making researchers more cautious when generalizing results of their models to real world (where environments are likely to abound with visual factors and substantially differ from a standard lab setting), if not contribute directly to the integration efforts (see  line~\lineref{call-to-action}).


\com[com-r1-acceptance]{There are reasonable responses to these questions, of course, and overall, the strengths of this ms outweigh the weaknesses. For those reasons I'm favorably inclined toward publication.}

Thank you for your positive evaluation, it is useful to know that we are on the right track.



% -----
% Reviewer 2
% -----

\section{Reviewer 2}
\label{rev:r2}

\subsection{Overall evaluation}
\label{rev:r2sum}

\com[com-r2-evaluation]{Thank you for submitting your paper on the role of visual attention in decision-making processes. I read the paper with a great interest. I agree with the authors that it is important to gather more insights into the role of visual attention in decision making and better understand the different factors that drive attention, particularly across disciplines. There are however some elements of the paper that could be further improved and some points that require clarification. Below I discuss major problems and auxiliary issues.} 

Thank you for your interest as well as for comments for improving the manuscript. We address each comment below. Please note that in the revised manuscript we introduced line numbers and for each comment we refer to a line in the document where we introduced a major change. To facilitate the revision we also marked major changes in the main text with red color.


\subsection{Comments}

\com[com-r2-methods-new-location]{First, the structure of the paper is quite surprising and makes following the authors' reasoning difficult. Including the method after the results and discussion forces the reader to search for information needed to understand what the authors did. Please change that.}

We have made the requested change, the method section now appears after the introduction, starting at line~\lineref{methods-new-location}.


\com[com-r2-discuss-visual-factors]{I also think that the authors should elaborate on the theoretical framework behind their study. While the authors provided a rather thorough literature review in the introduction, I missed a deeper discussion on the effects of visual factors, which would substantiate the relevance of the study.}

There are two paragraphs in the introduction that elaborate on the visual factors (starting at line~\lineref{vis-env}). Here we correct some of the issues you raise below and now we have strengthened the theoretical framework with a new third paragraph about the relation between visual and cognitive factors and how we expect that visual factors come to play a role in attention (starting at line~\lineref{natural-scene}). A short summary: We review literature from natural scene statistics to explain how visual factors come to play a role in attention from an evolutionary perspective, we also review studies on natural scene statistics in decision environments and have found very high correlations between visual factors like salience, surface size, and position, and decision relevant factors such as price, product popularity or product attributes. These ecological correlations probably makes visual factors efficient for guiding attention to relevant information and could explain why decision makers readily use visual factors.   


\com[com-r2-visual-elaborate]{I believe that the authors should elaborate on the visual factors more and earlier in the manuscript. I think 'silence' should be better defined, especially since the authors say in the discussion that "there are potentially other less researched visual factors not covered in our study that influence eye movements, e.g. motion or sudden onsets are known to capture eye movements involuntarily," but at the same time they claim that motion was coded as an element of silence: "We coded studies as salience if they operationalized one or more of the known dimensions of salience such as color, edge density, contrast, or motion."}

Thank you for raising these points. We have provided an operational definition of visual factors at the very beginning of the manuscript (see line~\lineref{visfac-def}). We have then added a more clear-cut definition of salience pointing out that it combines several low-level visual factors such as color, contrast, edge density, and motion (see line~\lineref{salience-def}). Finally, we have revised the sentence in the discussion which creates confusion about the operational definition of salience and the included factors (see line~\lineref{other-factors}). We have now pointed to possible visual factors that are not included in the definition of salience such as factors studied in natural scene statistics, light and shade, texture, or occlusion by objects, gestalt principles such as the laws of proximity, similarity, closure etc., or overall image properties such as feature or design complexity or visual clutter. 


\com[com-r2-visual-complexity]{Relatedly, it is not clear what the authors mean by 'visual complexity,' which seems to be more than the number of alternatives (see e.g. Pieters, Wedel, \& Batra, 2010).}

We have removed the sentence about visual complexity from the discussion of set size. As you point out, the explanation of these concepts was not clear. After considering this further, we believe that it does not follow that increasing the set size must increase visual clutter. If we are increasing the set size with objects that are similar in visual features then visual clutter should not change e.g., a notion similar to the concept "heterogeneity of brand background" in Pieters, Wedel, \& Batra, 2010. We therefore discuss visual clutter, feature complexity and design complexity as unexplored visual factors in the context of decision making (see line~\lineref{other-factors}).  


\com[com-r2-relation-salience-other-factors]{I think that when defying the studied factors, the authors should also explain what the relationship between silence and the other factors, such as surface size, is.}

We believe your question deserves a two-fold answer. On one hand, it is possible to operationalize visual factors independently of each other i.e., one can manipulate salience without influencing surface size, set size, or position. This means the visual factors can be made independent of each other in experimental designs. We have added this explanation to line~\lineref{independence}. On the other hand, in natural environments the visual factors are likely to be correlated with each other since we know that they correlate with common cognitive factors. For instance, popular products are more likely to have larger surface areas (number of facings) and also more likely to be positioned on top shelves in the supermarket. We have added this explanation in the new section describing the natural visual environment (see line~\lineref{dependence}). 


\com[com-r2-why-these-factors]{Finally, it is not entirely clear why the authors decided to study the chosen factors - that should be justified, especially since the authors suggest there are more relevant factors that can attract attention and affect decisions.}

Thank you for pointing this out. The reason for including the four visual factors is actually straightforward: as far as we know, these are the only visual factors studied in the context of decision making. We have stressed this at line ~\lineref{studiedfactors}. The cognitive factors are fairly broad in their definition and therefore capture most of the literature. We have explained this in the section dedicated to study approach at line~\lineref{factorinclusion}.


\com[com-r2-operationalize-decision-making]{In a similar vein, the authors should operationalize decision making at an earlier stage to help the reader understand the research inclusion criteria.}

We have moved the method section up so it appears before the results section (see line~\lineref{methods-new-location}). We hope this will help the reader to understand how we operationalize decision making and the inclusion criteria.  


\com[com-r2-publication-bias]{Could you also discuss the publication bias a) before presenting the results and b) more in depth? Why it occurs in this type of studies and what the plausible consequences are, as well as how the adjustment improved the analysis?}

We have now discussed the publication bias analysis in the method section which appears before the result section (see line~\lineref{pubbias-intro}). We hope this provides the necessary background for appreciating the analysis results. We have also extended both the analyses and the discussion of them as you propose. We have for instance, included a PET-PEESE analysis and new type of analysis based on the coding of studies citing public grants. We have extended the presentation of the publication bias results with these new analyses, using them to first verify that publication bias exists, before moving forward to the trim-and-fill correction procedure (see line~\lineref{PB-PET}). In the results section, the publication bias analyses appear after the main and moderator analyses since this is the most canonical order of presentation.


\com[com-r2-metric-correction]{The authors noted that there are many discrepancies in the literature when it comes to analyzing and reporting eye-tracking data. I agree. Researchers focus on different metrics. Also, since eye-tracking data are often skewed and zero inflated, different authors introduce different methods of analysis but also various transformations (such as logs, etc.), hence, the reported results are difficult to compare. How did the authors account for that? Was the introduced correction enough?}

As you point out, there is a wealth of different metrics and ways of handling eye tracking data. Fortunately, the vast majority of studies we identified reported results in either fixation likelihood, fixation count, total dwell time, or dwell count. Our section on multiple metrics in Methods section shows that effect sizes computed based on these four metrics are comparable with some adjustments. This is probably not true for other metrics e.g., we do not expect that time to first fixation, first dwell duration, dwell time proportion etc etc provide similar results. A few studies reported results in metrics other than the four included ones and consequently we had to exclude these. The answer to your question, therefore, is that not all metrics are comparable, but some metrics are after certain adjustments, and we focus only on the comparable metrics. To make the relation between effect sizes and underlying eye tracking metrics more transparent we have coded descriptive eye tracking metrics for all included studies. We have then written a new section (starting at line~\lineref{descriptiveEM-overview}) which shows how effect sizes are extracted from descriptive eye movement metrics and can be transformed back into absolute changes in fixation likelihood, fixation count, and total dwell time. This section also provides a more intuitive interpretation of the effect sizes. 


\com[com-r2-search-language]{Can you really claim that no restrictions on language were imposed, since the search terms were in English?}

You are right, we cannot make this claim and we have therefore deleted it from the section on literature search (see line~\lineref{litsearch}). 


\com[com-r2-socio-demographic]{On p 24. The authors state that they "excluded studies where participants were selected based on clinical diagnosis or specific socio-demographic traits e.g., visual disorders, age-related visual diseases, age restrictions such as adolescents or infants." What would be the reasons for removing certain age groups and what are the possible consequences? Were the samples that were not removed representative or were these mostly student samples? Could you share more information about the studied populations?}

The reason for these exclusion criteria was decided a priori since, for instance, participants with clinical diagnoses usually have very different eye movement patterns from non-clinical participants. We actually only excluded 3 studies on this account -- these were studies involving children.


\com[com-r2-focus-on-count]{I am also curious why the authors decided to focus on count measures rather than time, such as dwell time? The authors explain why they did not want fixation duration. Is it due to the ease of interpretation of count variables?}

We have expanded the section on multiple metrics to explain our reasons more clearly (see line~\lineref{metrics}). A brief summary of the revised paragraph is that both total dwell time and dwell count are composite metrics of fixation count with either fixation duration or inter-AOI transition count. This composite nature make them less construct valid in terms of the included visual and cognitive factors since fixation duration and inter-AOI transition count are diffusely related to the included visual and cognitive factors. Fixation likelihood is a discretization of fixation count, which leads to loss of information and underestimation when fixation counts are above 1 for all AOI's. In the end, fixation count is the only metric left that is easy to interpret, construct valid and will not underestimating effects due to discretization. 


\com[com-r2-low-icc]{Could you explain where such low ICC for the effect size comes from?}

We believe the reason for the low ICC for effect sizes is a combination of two factors: (1) the initial round of effect size coding was performed by a junior researcher, and (2) as you note above, eye tracking studies are very complex, often relying on multiple metrics, transformations etc. In the process of coding the descriptive eye tracking data the senior scientist responsible for this task also recoded effect sizes (blinded to the initial data). Testing the agreement between the original data and the recoded effect sizes shows that ICC is very high, ICC = .923, indicating a reliable data set. In revising the ICC we also realized that by mistake several variables were represented as ICC's even though they were kappas (see line~\lineref{reliability}).


\com[com-r2-final]{I hope my comments will help the authors move their work forward.}

We are grateful for your suggestions, they have definitely helped us to improve the manuscript.



% -----
% Reviewer 3
% -----

\section{Reviewer 3}
\label{rev:r3}

\subsection{Overall evaluation}
\label{rev:r3sum}

\com[com-r3-evaluation]{In the paper, the authors present a meta-analysis on factors influencing attention in decision making. The paper is overall very well done, makes several important methodological contributions and is very well written. Technically, this paper is also extremely sophisticated and I did not spot any substantial weakness concerning methodology. Overall, the paper has the potential to make a substantial contribution to the field and to be published in Psychological Bulletin after same revisions. In the revision, several issues should be addressed that mainly concern issues of clarification, presentation and discussion.} 

We thank you for your positive evaluation and suggestions for improving the manuscript. We address each comment below. Please note that in the revised manuscript we introduced line numbers and for each comment we refer to a line in the document where we introduced a major change. To facilitate the revision we also marked major changes in the main text with red color.


\subsection{Comments}

\com[com-r3-JDM-doesnt-care-about-attention]{The title and some other parts of the text are slightly misleading in that the induce higher expectations to which the paper cannot fully live up. It should be more clearly stated that the investigation is (only) concerned with effects on attention in choices and not with the - from a decision theoretic perspective - perhaps more important link between attention and choice. This also should be acknowledged in the discussion and other parts of the paper might be toned down a bit (e.g. policy significance statement). Most of the mentioned models (and other most prominent models in choice) do not really care overly much about attention and their predictions for it. They want to predict choices, sometimes also choice processes - attention is sometimes used to test process assumptions. This should be clarified. Also it should be acknowledged that from all we know so far the causal effects of attention on choice are tiny to not existing - at least if the studies use proper controls (e.g., Ghaffari \& Fiedler, 2018). It is still important to understand attention in choice processes but it also has to be stated that we can predict choice very well and close to choice reliability by our standard models without taking any attention effects into account (e.g., Glöckner \& Pachur, 2012; Glöckner, Hilbig \& Jekel, 2014). In the eye-tracking study contained in Glöckner et al. (2014), for example, there was a huge effect of environment on choice but no effect on attention. Hence, attention seems to often not even mediate effects of context factors on choice. This should be acknowledged as well. Still, it is certainly important to understand effects on attention in choice processes but these effects have to be discussed more in relation to the core aims of the models (predicting choice).}

Thank you for these comments. To keep a better overview, we answer them one at a time in the list below. 

1. We have changed the title to ``The visual environment and attention in decision making'', this makes it more precise that we are concerned with visual environment and attention in the context of decision making. We have also toned down our abstract and significance statement.

2. We now acknowledge at the very beginning of the manuscript that most decision research is concerned with predicting choices (see line~\lineref{r31}) and sometimes also choice processes, and that attention is then used to test process assumptions (see line~\lineref{r31b}).

3. Rather than open a discussion about the causal effect of attention on choice, which is outside the scope of the manuscript, we have decided to remove the claim about causal effects in the introduction (see line~\lineref{r32}).

4. We agree that attention is not necessarily useful for predicting choices. We have added a paragraph where we point this out and try to provide a few explanations why this could be the case (see line~\lineref{r33}). We would like to make two points, however. First, ability to predict choices really depends on a task -- accuracy can become fairly poor already in fairly standard multi-attribute choices. If we go slightly outside of classical lottery type of tasks and consider reinforcement learning tasks (which we, admittedly, do not consider here), taking into account attention can matter a lot. For example, \cite{stojic2020uncertainty} shows that with attention accuracy of predicting choices in multi-armed bandit tasks almost doubles. Second, your point serves very well to illustrate the point about the role of the visual environment. Our interpretation is that in standard JDM tasks in the lab the visual environment has no ecological validity in terms of relevant decision criteria (validity etc), in fact, visual factors are often explicitly controlled for. This could explain why decision makers might ignore visual factors in such tasks. \\


\com[com-r3-salience]{One problems with salience in the context of choice is that people deliberately try to counteract it since they might become aware of the manipulation intention, or they want to be rational and look at all information (at least once). At least in the simple standard paradigms, people mainly look up all information and then show double checking, which not necessarily have to do with the core of the decision process. It should be acknowledged that (a) it is therefore not surprising that effects of salience on attention are smaller in this context than in purely visual paradigms; (b) that people mainly look up all pieces of information at least once (the authors could provide a measure for this: the average dichotomous fixation rates (yes / no)). When just looking at the total number of fixations as it is done in the current analysis, (c) it is also not entirely clear what the attention tells us about the process since it often involves double checking and qualitatively different kinds of processes - sometimes involving long fixations indicating deliberate processes and sometimes shorter ones indicating scanning and double-checking even under typical deliberation instructions \citep[e.g.][]{horstmann2009}. Of course, the authors show a high correlation between various measures but it should be acknowledged that important process details are most likely missed.}

We have addressed your points in the following ways:\\
a) We have now discussed the possible effects of salience and visual factors in simple standard JDM paradigms and why salience may not have an effect here (see line~\lineref{r33}).\\ 
b) We have also discussed that decision makers are likely to attend to all information in these simple paradigms (also at line~\lineref{r33}). Your point about the dichotomous fixation rate took a good deal more space to clarify. First, we had to go back to the data and code descriptive statistics for all included studies. Based on this we wrote a new section on the descriptive eye movement statistics. The answer to your point is actually very surprising. It turns out that across all included studies providing descriptive statistics, the average dichotomous fixation rate (we refer to fixation likelihood) is only 61\% (see line~\lineref{descriptiveEM-overview}). So even though it may be true that fixation rates are nearly 100\% in studies with simple paradigms such as risky gambles, this is certainly not true in general of decision tasks.\\ 
c) We agree that important details may have been missed due to the selection of the dependent variables. However, many of these important metrics such as fixation duration and scanpath metrics such as the SI are reported in very few papers and do not lend themselves to a meta-analysis. We have added this paragraph to the discussion (see line~\lineref{r422c}). Regarding re-fixations, whether they should be classified as double checking, depends on precise setup and theoretical framework -- for example, modelling the decision process with sequential sampling model re-fixations are in fact part of the evidence accumulation, and hence speak directly about the process \citep[e.g.][]{krajbich2010a}. 


\com[com-r3-left-right]{The left vs. right distinction is a bit oversimplified since these effects mainly concern temporal dynamics and not an overall effect: people typically start reading left and then move to right and later to the emerging favored option (e.g., Fiedler \& Glöckner, 2011). Hence, a null effect is not overly surprising. Arguably, sometimes primacy or coherence effects influence choice processes and therefore the gaze-cascade effect might lead to a left looking bias overall - as found here. It is ok to report the effect as it is now but it should be acknowledged that this is a simplification and that there are reasonable process assumptions that might explain these effects relatively easily also within established models.}

We agree with your thoughts on the left vs right factor and have mentioned in the results that despite our null effect there might be temporal dynamics effect which are not covered in this meta-analysis (see line~\lineref{r423}). 


\com[com-r3-set-size]{I did not fully understand what the set size manipulation effect size means. This should be better explained. Describing an example study would be helpful - also for the manipulation of central position. Is it that fixations to EACH option reduces if more options are shown simultaneously on the screen? Since set size is numerical this could also be analyzed using absolute numbers of options (was this done here or just compared small vs. large?) -it would be great to give a bit more details; also to understand why for example Orquin found no effects at all whereas others found huge effects. I expect this not to be random.}

We have added more details to the method description of each independent variable (starting at line~\lineref{r424a}) to explain what the effect direction indicates. For set size we have also provided an example (see line~\lineref{r424d}). Basically, your interpretation is correct, a positive effect size indicates that fixations to each option are reduced with larger set sizes by comparing small vs large sets. We do not compare sets based on absolute numbers since some studies operationalize set size in number of attributes and some in number of alternatives. When split by this alternative vs attribute moderator, there are not enough studies to meaningfully perform a meta-regression, but we do compare the effect sizes when split by this factor. Future studies could examine this question in more depth using our descriptive data for the studies reporting an overall fixation likelihood. However, this would require coding the set size - a task which may turn out to be infeasible since not all authors report sufficient details about properties of the stimuli, definition of AOI's etc. 


\com[com-r3-descriptive-data]{I highly appreciate that the data is shared, but the provided data is on a very high level aggregated and descriptions for the variables are missing (code book). In the current form, the data cannot really be used for further questions that researchers (like I) might have to understand what is going on. This should be improved. If available less aggregated or if possible even raw data should be provided.}

Following your suggestion we have coded raw data where reported. More specifically, we have extracted raw eye movement measures that underlie the effect sizes -- fixation likelihood, count and dwell time per condition per study (see a new section in Methods, beginning at line~\lineref{descriptiveEM-coding}). Hopefully this extended data set will allow other researchers to reuse our data more easily.\\

We also realised that we could use the new data to improve our understanding of the results. Details on this analysis can be found in a new section in Methods, beginning at line~\lineref{descriptiveEM-analysis}, and we have reported these results in a new section in Results, beginning at line~\lineref{descriptiveEM-overview}.
First, we have provided simple distribution plots and averages which allow the reader to get a sense of how the raw data is associated with the effect sizes (Figure~\ref{fig:em_figure}, panels A-C). For example, one can see that there is a lot of variance in fixation likelihood across studies -- in some studies participants fixate nearly all AOI's, but there is also a large number of studies in which participants fixate half or less of the AOI's. Second, we transform the synthesized effect sizes for each independent variable into its corresponding effect on fixation likelihood, fixation count and total dwell time. We achieve this by regressing descriptive measures (appropriately transformed) on effect size correlations, using a linear mixed model with a random intercept, grouped by article to account for correlated errors. Overall, all three measures strongly correlate with the (transformed) effect sizes, giving us confidence for converting effect sizes into original measures using the fitted models. Table~\ref{tab:em_results} reports results which the reader can use to more intuitively compare the effect sizes for each independent variable in terms of the equivalent effect on fixation likelihood, fixation count, and total dwell time.\\

Finally, we have provided a code book in the Open source framework repository, alongside the data file -- thank you for spotting this omission.


\com[com-r3-choice-bias]{I found it unfortunate, that the gaze cascade effect is renamed in choice bias. This implies - due to conventional use - that there is a bias in choice, but this is not what is meant by it in the current context. The authors might consider using a different term or at least to add in the main tables and figures are reference to the classic term. Recently, a process model with an even more detailed prediction concerning information search, the attraction search effect, has been proposed and empirically validated (Jekel et al., 2018). This should be briefly discussed as well in the GD as current model development.}

We agree that the name ``choice bias'' is potentially misleading and now refer to this factor as ``choice-gaze effect''. We have integrated a paragraph of the PCS model and the interesting attraction search effect in the discussion. We also suggest that the model and the implication for attraction search may potentially provide the necessary background for explaining the effect of preferential viewing  as well (see line~\lineref{r426}).  

\com[com-r3-interactive-activation]{I was missing in the GD a brief discussion concerning the link between models for perception (e.g. McClelland / Biederman / Kintsch etc.) and choice - mentioning classic interactive activation models. Some models try to bridge the gap by using essentially the same processes in both contexts, while other assume very different processes in higher cognition (i.e. decision making). A brief discussion would be warranted given the broad readership of this journal.}

We agree that this is a interesting and promising avenue and have added a paragraph to the discussion about the relevance of bridging the perceptual and choice domain (see line~\lineref{r427}). 

\clearpage


% -------------------------------------------------------
% Introduction
% -------------------------------------------------------

% part necessary to accommodate differences between review section and main text
\doublespacing
\setcounter{page}{1}
\setcounter{secnumdepth}{0}